
---
## Эксперимент: "Сортировка с отвлекающими факторами"

**Цель:** Сравнить способность классического Трансформера и DAT к решению задачи, где сложность вычислений зависит от входных данных.

**Задача:** Модель получает на вход последовательность чисел и должна классифицировать её по одному признаку: **является ли последовательность отсортированной по возрастанию?**

**"Изюминка" задачи:** Чтобы проверить, как модели справляются с "шумом", мы будем добавлять в последовательность "отвлекающие" токены-буквы. Сложность задачи напрямую зависит от количества этого шума.

* **Простой пример (мало вычислений):** `[CLS] 1 2 5 8 9 [SEP]` -> **Класс: 1 (отсортировано)**
* **Сложный пример (много вычислений):** `[CLS] 4 a 1 z 8 b 2 [SEP]` -> **Класс: 0 (не отсортировано)**

**Гипотеза:** DAT должен научиться использовать меньше слоёв для простых, "чистых" последовательностей и больше — для "зашумлённых", в то время как классический Трансформер будет тратить одинаковое количество ресурсов на все примеры.

---
### Фаза 1: Подготовка (≈ 1 час)

1.  **Генерация данных:**
    * Напишите простой Python-скрипт, который генерирует 3 набора данных (train, validation, test) по 10,000 последовательностей в каждом.
    * **Параметры генерации:**
        * Длина последовательности: случайная, от 10 до 40 токенов.
        * Числа: от 0 до 999.
        * "Шум": случайное количество букв (от 0% до 50% от длины).
        * Метка: `1`, если числа в последовательности идут по возрастанию, иначе `0`.
    * Сохраните данные в удобном формате (например, `.pt` файлы PyTorch).

2.  **Настройка моделей:**
    * **Модель А (Baseline):** Классический Трансформер. Его можно легко сделать из вашего `dat_core.py`, создав `EncoderConfig`, где все адаптивные функции отключены (`halt_gate_hidden=None`, `head_gate_hidden=None`).
    * **Модель Б (DAT):** Ваша полная реализация `DynamicEncoder`.
    * **Конфигурация (для обеих моделей):**
        * `n_layers`: 4 (небольшая глубина для скорости)
        * `d_model`: 256
        * `n_heads`: 4
        * `d_ff`: 1024
    * **Важно:** Убедитесь, что общее количество параметров у обеих моделей примерно одинаково.

3.  **Настройка трейнера:**
    * Используйте ваш `dat_train_scratch.py`. Он идеально подходит.
    * Задача — `task="classification"`, но не по каждому токену, а по всей последовательности. Для этого нужно немного изменить "голову" модели, чтобы она делала предсказание на основе вектора `[CLS]` токена.

---
### Фаза 2: Обучение (≈ 4-6 часов на каждую модель)

1.  **Обучение Baseline:**
    * Запустите обучение модели А на сгенерированном датасете.
    * Установите `max_steps` на ~10,000-15,000. Этого должно хватить, чтобы увидеть сходимость.
    * Периодически сохраняйте модель и логируйте точность на валидационном наборе.

2.  **Обучение DAT:**
    * Запустите обучение модели Б с **теми же самыми** гиперпараметрами (learning rate, batch size и т.д.).
    * **Важно:** Включите все регуляризационные штрафы (`depth_w`, `head_l1_w` и т.д.), чтобы поощрять модель быть экономной.
    * Также сохраняйте и логируйте всё.

---
### Фаза 3: Оценка и Анализ (≈ 2 часа)

Загрузите лучшие чекпоинты обеих моделей (по валидационной точности).

1.  **Сравнение качества:**
    * Посчитайте и сравните итоговую **точность (accuracy)** обеих моделей на тестовом наборе.

2.  **Сравнение эффективности (самое интересное):**
    * Разделите тестовый набор на две части: **"чистые"** (0-10% шума) и **"зашумлённые"** (40-50% шума).
    * **Для Baseline:** Измерьте среднее время инференса (inference time) на "чистых" и "зашумлённых" данных. Оно должно быть примерно одинаковым.
    * **Для DAT:**
        * Включите режим `early_exit=True`.
        * Измерьте среднее время инференса на "чистых" и "зашумлённых" данных. **Оно должно быть разным!**
        * Посчитайте **среднюю использованную глубину (`expected_depth`)** для "чистых" и "зашумлённых" данных. Вы должны увидеть, что на "чистых" данных DAT использует значительно меньше слоёв.

---

### Результат

| Модель       | Общая точность | Точность (Легкие) | Точность (Сложные) | Глубина (Легкие) | Глубина (Сложные) | Скорость (Легкие), мс | Скорость (Сложные), мс |
|:-------------|:---------------|:------------------|:-------------------|:-----------------|:------------------|----------------------:|-----------------------:|
| **Baseline** | 0.9450 | 0.9958 | 0.9280 | — | — | 0.030 | 0.060 |
| **DAT** | 0.6840 | 0.6920 | 0.6780 | 0.892 | 1.032 | 0.032 | 0.048 |

### Настройки сети (run)
| Параметр   | Значение |
|:-----------|---------:|
| d_model    | 33 |
| n_heads    | 3 |
| n_layers   | 4 |
| d_ff       | 99 |
| max_len    | 64 |
| vocab_size | 4 |

### Результат

| Модель       | Общая точность | Точность (Легкие) | Точность (Сложные) | Глубина (Легкие) | Глубина (Сложные) | Скорость (Легкие), мс | Скорость (Сложные), мс |
|:-------------|:---------------|:------------------|:-------------------|:-----------------|:------------------|----------------------:|-----------------------:|
| **Baseline** | 0.6360 | 0.6540 | 0.6257 | — | — | 0.014 | 0.039 |
| **DAT** | 0.9985 | 1.0000 | 0.9986 | 0.834 | 0.854 | 0.021 | 0.034 |

### Настройки сети (run)
| Параметр   | Значение |
|:-----------|---------:|
| d_model    | 32 |
| n_heads    | 2 |
| n_layers   | 4 |
| d_ff       | 64 |
| max_len    | 64 |
| vocab_size | 4 |

